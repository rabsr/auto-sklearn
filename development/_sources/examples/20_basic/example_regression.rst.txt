.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_20_basic_example_regression.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_examples_20_basic_example_regression.py:


==========
Regression
==========

The following example shows how to fit a simple regression model with
*auto-sklearn*.




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.8.6/x64/lib/python3.8/site-packages/pyparsing.py:3190: FutureWarning: Possible set intersection at position 3
      self.re = re.compile(self.reString)
    [WARNING] [2020-12-11 16:03:30,885:autosklearn.metalearning.optimizers.metalearn_optimizer.metalearner] Configuration 45 not found
    [WARNING] [2020-12-11 16:03:30,885:autosklearn.metalearning.optimizers.metalearn_optimizer.metalearner] Configuration 17 not found
    [WARNING] [2020-12-11 16:03:30,887:autosklearn.metalearning.optimizers.metalearn_optimizer.metalearner] Configuration 24 not found
    [(0.340000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'select_rates_regression', 'regressor:__choice__': 'adaboost', 'feature_preprocessor:select_rates_regression:alpha': 0.1315448785615316, 'feature_preprocessor:select_rates_regression:mode': 'fwe', 'feature_preprocessor:select_rates_regression:score_func': 'f_regression', 'regressor:adaboost:learning_rate': 0.10918120508145727, 'regressor:adaboost:loss': 'square', 'regressor:adaboost:max_depth': 9, 'regressor:adaboost:n_estimators': 50},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.200000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'libsvm_svr', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.014087234899150132, 'regressor:libsvm_svr:C': 243.80018215429655, 'regressor:libsvm_svr:epsilon': 0.0010313680328976054, 'regressor:libsvm_svr:kernel': 'rbf', 'regressor:libsvm_svr:max_iter': -1, 'regressor:libsvm_svr:shrinking': 'True', 'regressor:libsvm_svr:tol': 0.0003015355281210108, 'regressor:libsvm_svr:degree': 5, 'regressor:libsvm_svr:gamma': 0.12602136380125653},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.180000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'gradient_boosting', 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1425, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'feature_preprocessor:feature_agglomeration:affinity': 'cosine', 'feature_preprocessor:feature_agglomeration:linkage': 'complete', 'feature_preprocessor:feature_agglomeration:n_clusters': 276, 'feature_preprocessor:feature_agglomeration:pooling_func': 'max', 'regressor:gradient_boosting:early_stop': 'off', 'regressor:gradient_boosting:l2_regularization': 0.00018459550741867383, 'regressor:gradient_boosting:learning_rate': 0.04757728173371449, 'regressor:gradient_boosting:loss': 'least_squares', 'regressor:gradient_boosting:max_bins': 255, 'regressor:gradient_boosting:max_depth': 'None', 'regressor:gradient_boosting:max_leaf_nodes': 16, 'regressor:gradient_boosting:min_samples_leaf': 6, 'regressor:gradient_boosting:scoring': 'loss', 'regressor:gradient_boosting:tol': 1e-07},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.120000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'none', 'feature_preprocessor:__choice__': 'select_rates_regression', 'regressor:__choice__': 'adaboost', 'feature_preprocessor:select_rates_regression:alpha': 0.13294870400704156, 'feature_preprocessor:select_rates_regression:mode': 'fwe', 'feature_preprocessor:select_rates_regression:score_func': 'f_regression', 'regressor:adaboost:learning_rate': 0.47982456668237294, 'regressor:adaboost:loss': 'square', 'regressor:adaboost:max_depth': 10, 'regressor:adaboost:n_estimators': 143},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.120000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'fast_ica', 'regressor:__choice__': 'gradient_boosting', 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.7049491520337817, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.23602880130851764, 'feature_preprocessor:fast_ica:algorithm': 'deflation', 'feature_preprocessor:fast_ica:fun': 'cube', 'feature_preprocessor:fast_ica:whiten': 'False', 'regressor:gradient_boosting:early_stop': 'off', 'regressor:gradient_boosting:l2_regularization': 4.696295762197504e-10, 'regressor:gradient_boosting:learning_rate': 0.03269357604116943, 'regressor:gradient_boosting:loss': 'least_squares', 'regressor:gradient_boosting:max_bins': 255, 'regressor:gradient_boosting:max_depth': 'None', 'regressor:gradient_boosting:max_leaf_nodes': 32, 'regressor:gradient_boosting:min_samples_leaf': 14, 'regressor:gradient_boosting:scoring': 'loss', 'regressor:gradient_boosting:tol': 1e-07},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    (0.040000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'feature_agglomeration', 'regressor:__choice__': 'gradient_boosting', 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1070, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'feature_preprocessor:feature_agglomeration:affinity': 'manhattan', 'feature_preprocessor:feature_agglomeration:linkage': 'average', 'feature_preprocessor:feature_agglomeration:n_clusters': 197, 'feature_preprocessor:feature_agglomeration:pooling_func': 'median', 'regressor:gradient_boosting:early_stop': 'off', 'regressor:gradient_boosting:l2_regularization': 5.517307840898784e-08, 'regressor:gradient_boosting:learning_rate': 0.9960837057516964, 'regressor:gradient_boosting:loss': 'least_squares', 'regressor:gradient_boosting:max_bins': 255, 'regressor:gradient_boosting:max_depth': 'None', 'regressor:gradient_boosting:max_leaf_nodes': 4, 'regressor:gradient_boosting:min_samples_leaf': 13, 'regressor:gradient_boosting:scoring': 'loss', 'regressor:gradient_boosting:tol': 1e-07},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    ]
    R2 score: 0.8958653172785895






|


.. code-block:: default

    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.regression


    if __name__ == "__main__":
        ############################################################################
        # Data Loading
        # ============

        X, y = sklearn.datasets.load_boston(return_X_y=True)

        X_train, X_test, y_train, y_test = \
            sklearn.model_selection.train_test_split(X, y, random_state=1)

        ############################################################################
        # Build and fit a regressor
        # =========================

        automl = autosklearn.regression.AutoSklearnRegressor(
            time_left_for_this_task=120,
            per_run_time_limit=30,
            tmp_folder='/tmp/autosklearn_regression_example_tmp',
            output_folder='/tmp/autosklearn_regression_example_out',
        )
        automl.fit(X_train, y_train, dataset_name='boston')

        ############################################################################
        # Print the final ensemble constructed by auto-sklearn
        # ====================================================

        print(automl.show_models())

        ###########################################################################
        # Get the Score of the final ensemble
        # ===================================

        predictions = automl.predict(X_test)
        print("R2 score:", sklearn.metrics.r2_score(y_test, predictions))


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  55.311 seconds)


.. _sphx_glr_download_examples_20_basic_example_regression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_regression.py <example_regression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_regression.ipynb <example_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
